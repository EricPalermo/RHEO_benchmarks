{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766b0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4570590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and apply style file for plots\n",
    "plt.style.use(\"mpl.style\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e18ed1-56e1-4291-80e1-7aa7758b303f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/epalermo/dev/rheo_bench/jpynb_scripts'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd = os.getcwd()\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02798b",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [Functions](#Functions)\n",
    "    * [General](#general)\n",
    "        * [File Handling](#file_handling)\n",
    "        * [Extract LAMMPS Data](#extract_LAMMPS_data)\n",
    "        * [Plotting](#plotting)\n",
    "* [Test Cases](#test_cases)\n",
    "    * [Taylor-Green Vortex](#TG_funcs)\n",
    "    * [Poiseuille Flow](#PF_funcs)\n",
    "    * [Extended Droplet](#ED_funcs)\n",
    "    * [Kernel Convergence - Velocity Gradient](#gradv_funcs)\n",
    "    * [Kernel Convergence - Surface Normals](#surf_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d2013",
   "metadata": {},
   "source": [
    "# Functions <a class=\"anchor\" id=\"Functions\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad0656",
   "metadata": {},
   "source": [
    "### File Handling <a class=\"anchor\" id=\"file_handling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3dcaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compile all filenames in a given directory into a dictionary\n",
    "#value=filepath, key = run properties\n",
    "def generate_file_names(filepath):\n",
    "    data_files = {}\n",
    "\n",
    "    for file in os.listdir(filepath):\n",
    "\n",
    "        #Remove the .nc extension\n",
    "        run_code = file.split(\".\")[0]\n",
    "\n",
    "        #Add the files to datafiles dictionary\n",
    "        data_files[run_code]= filepath + \"/\" + file\n",
    "    return data_files\n",
    "\n",
    "#Collect run info from a file name\n",
    "def parse_file_name(run):\n",
    "    run_info_coded = run.split(\"_\")\n",
    "    #Parse the string and perform type conversions and calculations\n",
    "    run_info_decoded = [] #to be stored in a df\n",
    "    numerical_params = {} #to be used in scaling calculations\n",
    "    for count, param in enumerate(run_info_coded):\n",
    "        #Handling depends on the variable\n",
    "        if namekey[count] == \"var0\":\n",
    "            run_info_decoded.append(var0_key[param])\n",
    "        elif namekey[count] == \"kernel_type\":\n",
    "            run_info_decoded.append(var1_key[param])\n",
    "        elif namekey[count] == \"sf\":\n",
    "            sf = 1/int(param)\n",
    "            run_info_decoded.append(sf)\n",
    "            numerical_params[namekey[count]]=sf\n",
    "        elif namekey[count] == \"hd\":\n",
    "            hd = param.replace(\"p\",\".\")\n",
    "            hd = float(hd)\n",
    "            run_info_decoded.append(hd)\n",
    "            numerical_params[namekey[count]]=hd\n",
    "        elif namekey[count] == \"eta\":\n",
    "            eta = param.replace(\"p\",\".\")\n",
    "            eta = float(eta)\n",
    "            run_info_decoded.append(eta)\n",
    "            numerical_params[namekey[count]]=eta\n",
    "        elif namekey[count] == \"fext\":\n",
    "            fext = float(param)\n",
    "            run_info_decoded.append(fext)\n",
    "        else:\n",
    "            print(\"missing param key\")\n",
    "    run_info_decoded.append(run)\n",
    "    \n",
    "    return run_info_decoded,numerical_params\n",
    "\n",
    "\n",
    "#Calculate any dependent vars\n",
    "def dependent_vars(numerical_params):\n",
    "    L_z = h3*(d-2)*sf #Account for L_z if d=3\n",
    "    n = 1/sf**d #Number density - number of particles per volume\n",
    "    mp = rho0/n #Mass of particles (density is constant)\n",
    "    if d == 3:\n",
    "        N = R*R*L_z/sf**d # Total number of atoms\n",
    "    elif d == 2:\n",
    "        N = R*R/sf**d \n",
    "    return numerical_params\n",
    "\n",
    "# def gather_run_info(run,data_files):\n",
    "#     run_info, numerical_params = parse_file_name(run)\n",
    "#     ds = Dataset(data_files[run])\n",
    "#     mp, N = scaling_vars(run)\n",
    "#     run_info.append(sf)\n",
    "\n",
    "#     return run_info, ds, sf, mp, N\n",
    "\n",
    "def gen_col_names(namekey):\n",
    "    col_names = namekey\n",
    "    col_names.append(\"run_code\")\n",
    "    return col_names\n",
    "\n",
    "def generate_df(data_files,col_names):\n",
    "    df =pd.DataFrame(columns=col_names)\n",
    "    for run in data_files:\n",
    "    #Gather run info from the file name\n",
    "        run_info, numerical_params = parse_file_name(run)\n",
    "        ds = Dataset(data_files[run])\n",
    "        run_df = {}\n",
    "        for count,value in enumerate(run_info):\n",
    "            run_df[col_names[count]]=value\n",
    "        df = df.append(run_df,ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e2e6a",
   "metadata": {},
   "source": [
    "### LAMMPS Data Calculations <a class=\"anchor\" id=\"extract_LAMMPS_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818a2ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Returns coordinates and velocities for all particles at each timestep\n",
    "def extract_velocity_data(ds):\n",
    "    td = ds[\"time\"][:]\n",
    "    xd = ds['coordinates'][:,:,0] #At timestep nf, for all particles, x position\n",
    "    yd = ds[\"coordinates\"][:,:,1] #At timestep nf, for all particles, y position\n",
    "    vxd = ds[\"velocities\"][:,:,0] #At timestep nf, for all particles, x position\n",
    "    vyd = ds['velocities'][:,:,1] #At timestep nf, for all particles, y velocity\n",
    "    return td,xd,yd,vxd,vyd\n",
    "\n",
    "def calc_KE(td,xd,yd,vxd,vyd,mp):\n",
    "    Exd = 0.5*mp*(np.sum(np.abs(vxd), axis=1))**2\n",
    "    Eyd = 0.5*mp*(np.sum(np.abs(vyd), axis=1))**2\n",
    "    E_tot = Exd+Eyd\n",
    "    return E_tot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0fc83",
   "metadata": {},
   "source": [
    "### Plotting <a class=\"anchor\" id=\"plotting\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c725834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot types\n",
    "\n",
    "#Normalized Error Plot#\n",
    "#Input is a dataframe with columns [\"shifting\",\"CRK\",\"sf\",\"L1 norm\"]\n",
    "#L1 will vary, e.g. viscosity, surface normal, velocity gradient, etc.\n",
    "def plot_normalized_error(all_run_info):\n",
    "    df = pd.DataFrame(all_run_info, columns=[\"var0\",\"CRK\",\"sf\",\"Surf Normal Normalized Error\"])    \n",
    "    #df.sort_values(by=[\"sf\",\"CRK\"], inplace=True)\n",
    "    df.sort_values(by=[\"sf\"], inplace=True)\n",
    "    L1_label = df.iloc[:,-1:].columns[0]\n",
    "    for i in df[\"var0\"].unique():\n",
    "        df_1 = df[df[\"var0\"]==i]\n",
    "        for j in df_1[\"CRK\"].unique():\n",
    "            df_2 = df_1[df_1[\"CRK\"]==j]\n",
    "            df_2 = df_2.sort_values(by=[\"sf\"])\n",
    "            label = j\n",
    "            plt.loglog(R/df_2[\"sf\"],df_2[L1_label],\n",
    "                       marker=plot_key[j][0],\n",
    "                       linestyle=plot_key[i],\n",
    "                       markerfacecolor=\"None\",\n",
    "                       color=plot_key[j][1],\n",
    "                       label=label)\n",
    "            #print(df_2)\n",
    "            \n",
    "\n",
    "#Generic y vs x profile (e.g. velocity vs time)        \n",
    "def plot_profile(x,y,run_info, ax, plot_type, plot_key):\n",
    "    ax = ax\n",
    "    if plot_type == \"data\":\n",
    "        ax.plot(x, y,\n",
    "                        linestyle=plot_key[run_info[0]],\n",
    "                        marker=plot_key[run_info[1]][0],\n",
    "                        markevery=0.2,\n",
    "                        markerfacecolor=\"None\",\n",
    "                        color=plot_key[run_info[1]][1],\n",
    "                        label = run_info[1])\n",
    "    if plot_type == \"analytic\":\n",
    "        ax.plot(x, y,\n",
    "                   label = \"Analytic\",\n",
    "                   color=\"red\",\n",
    "                   linestyle=\"solid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfd3487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot formatting\n",
    "\n",
    "#Retrieve the default labels and handles\n",
    "def order_labels(ax):\n",
    "    label_order_dict = {\"Quintic\":0,\"CRK0\":1,\"CRK1\":2,\"CRK2\":3,\"Analytic\":4,\"other\":5}\n",
    "    handles,labels = ax.get_legend_handles_labels()\n",
    "    label_order_unsorted = []\n",
    "    labels_sorted = []\n",
    "    for label in labels:\n",
    "        if label in label_order_dict:\n",
    "            label_order_unsorted.append([label_order_dict[label],label])\n",
    "        else:\n",
    "            label_order_unsorted.append([label_order_dict[\"other\"],label])\n",
    "    label_order_sorted = sorted(label_order_unsorted)\n",
    "    for label in label_order_sorted:\n",
    "        labels_sorted.append(label[1])\n",
    "\n",
    "    handle_dict = dict(zip(labels,handles))\n",
    "    handles_sorted = []\n",
    "    for i in labels_sorted:\n",
    "        handles_sorted.append(handle_dict[i])\n",
    "    \n",
    "    return handles_sorted, labels_sorted\n",
    "\n",
    "#Generate custom plot handles for the given labels\n",
    "def generate_handles(ax):\n",
    "    handles,labels = order_labels(ax)\n",
    "    labels_unique = [x for i, x in enumerate(labels) if labels.index(x) == i]\n",
    "    custom_handles = []\n",
    "    for label in labels_unique:\n",
    "        custom_handles.append(Line2D((0,1), (0,0), color=plot_key[label][1], marker=plot_key[label][0], markerfacecolor=\"None\", label=label))\n",
    "    for i in var_0_key:\n",
    "        custom_handles.append(Line2D((0,1), (0,0), color=\"black\", linestyle=plot_key[i],  markerfacecolor=\"None\",label=var_0_key[i]))\n",
    "    return custom_handles\n",
    "        \n",
    "\n",
    "#Manually change the plot format to suit the data\n",
    "def format_plot(fig, ax, plot_params):\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        #Axis labels and limits\n",
    "        x_lab,y_lab,x_lim,y_lim,legend_loc = plot_params[i]\n",
    "        ax.set_xlabel(x_lab)\n",
    "        ax.set_ylabel(y_lab)\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "        #Legend\n",
    "        handles = generate_handles(ax)\n",
    "        ax.legend(handles=handles, loc=legend_loc)\n",
    "    if type(ax)=='numpy.ndarray':\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3edae3-b8ce-4c56-913c-e4ef69f53d95",
   "metadata": {},
   "source": [
    "# Poiseuille Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b437bf2c-15d4-4914-822d-81870acd6f64",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5932f903-b4bb-4f26-9541-1eeb3ffc66e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Analytical solution for Newtonian Poiseuille Flow in 2D rectangular channel \n",
    "def poiseuille_analyt(r,t,model):\n",
    "    P_grad = -f_ext\n",
    "    if model == \"Newtonian\":\n",
    "        eta = 1 #eta cancels out when normalizing\n",
    "        u_z = 0.5/eta*(-P_grad)*(R**2-r**2) \n",
    "    elif model == \"Power Law\":\n",
    "        u_z = npow/((2*k)**(1/npow)*(npow+1))*(-P_grad)**(1/npow)*(R**(1/npow+1)-(np.abs(r))**(1/npow+1))        \n",
    "    u_z_norm = u_z/np.max(u_z)\n",
    "    return u_z_norm\n",
    "\n",
    "def poiseuille_data(run, ds):\n",
    "    #list of all atoms\n",
    "    atom_ids = ds[\"id\"][frame]\n",
    "    #list of flow atoms\n",
    "    flow_atom_ids = []\n",
    "\n",
    "    #iterate over each atom\n",
    "    for count, atom in enumerate(atom_ids):\n",
    "        if ds[\"type\"][int(frame),int(atom)-1]==1:\n",
    "            flow_atom_ids.append(atom)\n",
    "\n",
    "\n",
    "    t_frame = ds[\"time\"][frame]\n",
    "\n",
    "    u_z = np.zeros(shape=len(flow_atom_ids))\n",
    "    r = np.zeros(shape=len(flow_atom_ids))\n",
    "    for count, atom in enumerate(flow_atom_ids):\n",
    "        r[count] = ds[\"coordinates\"][frame,atom-1,1]\n",
    "        u_z[count] = ds[\"velocities\"][frame,atom-1,0]\n",
    "    \n",
    "    return t_frame, r, u_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bde442-c267-4b1f-924c-1331ef23b4ea",
   "metadata": {},
   "source": [
    "## Channel Parameters\n",
    "Common among all LAMMPS input scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d20a21a-c8b8-412d-a110-a64e10b03107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Test-specific keys\n",
    "#################################\n",
    "namekey = [\"var0\",\"kernel_type\",\"sf\",\"hd\",\"eta\",\"fext\"]\n",
    "var1_key = {\"5\":\"Quintic\",\"0\":\"CRK0\", \"1\":\"CRK1\", \"2\":\"CRK2\"}\n",
    "var0_key = {\"0\":\"Newtonian\",\"1\":\"Power Law\"} #Viscosity calc method\n",
    "plot_key = {\"Quintic\":[\"o\",\"#5ec962\"],\"CRK0\":[\"X\",\"#21918c\"], \"CRK1\":[\"s\",\"#3b528b\"],\"CRK2\":[\"d\",\"#440154\"],\n",
    "            \"Analytic\":[\"\",\"red\"],\"0\":\"dashed\",\"1\":\"dotted\"} #Viridis colors\n",
    "#################################\n",
    "# Simulation parameters\n",
    "#################################\n",
    "#System dimensions\n",
    "outer_R = 10\n",
    "R = 6.99\n",
    "d = 3 #3d\n",
    "#Fluid properties\n",
    "rho0 = 1\n",
    "gd0 = 1e-2\n",
    "npow=0.5\n",
    "#Scaling parameters\n",
    "nb =1\n",
    "#Frame (5 before end)\n",
    "frame = -1 #corresponds to t=3500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e797a-d112-4e42-8e7d-b1cd36788c86",
   "metadata": {},
   "source": [
    "# Channel Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00468c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "939a64fe-20c5-441b-b8ca-faa217141477",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20819/138353076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#data for ss_data_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"velocities\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmax_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "#Specify filepath\n",
    "infilepath = '/home/epalermo/dev/rheo_bench/poiseuille_flow/wall_debug_03_25/ncdf/'\n",
    "#Create dataframe of simulation parameters and run code for all runs\n",
    "data_files = generate_file_names(infilepath)\n",
    "generate_df(data_files,gen_col_names(namekey))\n",
    "#Create dictionary to store simulation data\n",
    "ss_data_dict = {} #dict for max velocity vs time data (to check steady state)\n",
    "uprof_data_dict = {} #dict for velocity as a function of x\n",
    "#Extract simulation data\n",
    "for run in data_files:\n",
    "    #data for ss_data_dict\n",
    "    u = ds[\"velocities\"][:,:,0]\n",
    "    max_u = np.max(u,axis=1)\n",
    "    t = ds[\"time\"][:]\n",
    "    t_prof = np.hstack((t[:,None],max_u[:,None]))\n",
    "    t_prof = t_prof[t_prof[:,0].argsort()]\n",
    "    ss_data_dict[run_info[-1]]=t_prof \n",
    "    \n",
    "    #data for uprof_data_dict    \n",
    "    t_frame, r, u_z = poiseuille_data(run, ds)\n",
    "    r_norm = r/R\n",
    "    u_z_norm = u_z/np.max(u_z)\n",
    "    #Reformat the data for plotting\n",
    "    u_prof = np.hstack((r_norm[:,None],u_z_norm[:,None]))\n",
    "    u_prof = u_prof[u_prof[:,0].argsort()]\n",
    "    #Only need R>0 because the data is symmetrical\n",
    "    u_prof = u_prof[np.logical_not(u_prof[:,0] < 0)]\n",
    "    uprof_data_dict[run_info[-1]]=u_prof "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c38833",
   "metadata": {},
   "source": [
    "#### Steady State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3fab6-fb64-44b8-b53c-ddc91c276afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ext = 0.00001\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,7.5))\n",
    "\n",
    "for row in df.itertuples():\n",
    "    profile = ss_data_dict[row.run_code]\n",
    "    ax.plot(profile[:,0],profile[:,1],label=[row.var0,row.kernel_type])\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(r\"$\\frac{r}{R}$\")\n",
    "\n",
    "ax.set_ylabel(r\"$\\frac{u}{u_{max}}$\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a6f69",
   "metadata": {},
   "source": [
    "#### Velocity Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e3ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\"Newtonian\",\"Power Law\"]\n",
    "fig, ax = plt.subplots(len(model_list),1,figsize=(15,15),sharex=True)\n",
    "\n",
    "for count,value in enumerate(model_list):\n",
    "    subdf = df.loc[(df.var0==value)]\n",
    "    for row in subdf.itertuples():\n",
    "        profile = uprof_data_dict[row.run_code]\n",
    "        ax[count].plot(profile[:,0],profile[:,1],label=[row.var0,row.kernel_type])\n",
    "\n",
    "    #analytical\n",
    "    r_ref = np.linspace(0,R,25)\n",
    "    r_ref_norm = r_ref/R\n",
    "    u_z_ref_norm = poiseuille_analyt(r_ref, t_frame, \"Newtonian\")\n",
    "\n",
    "    u_prof_analyt = np.hstack((r_ref_norm[:,None],u_z_ref_norm[:,None]))\n",
    "    u_prof_analyt = u_prof_analyt[u_prof_analyt[:,0].argsort()] \n",
    "\n",
    "    #Plot\n",
    "    plot_profile(u_prof_analyt[:,0],u_prof_analyt[:,1],run_info, ax[count], \"analytic\",plot_key)\n",
    "\n",
    "    ax[count].legend(loc=\"lower left\")\n",
    "    ax[count].set_xlabel(r\"$\\frac{r}{R}$\")\n",
    "    \n",
    "ax[0].set_ylabel(r\"$\\frac{u}{u_{max}}$\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae87a1b",
   "metadata": {},
   "source": [
    "# Dam Break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c454b319",
   "metadata": {},
   "source": [
    "## Hydrostatic Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29731fd6-ff1b-4221-b612-811b61fe262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Test-specific keys\n",
    "#################################\n",
    "namekey = [\"var0\",\"kernel_type\",\"sf\",\"hd\",\"eta\",\"fext\"]\n",
    "var1_key = {\"5\":\"Quintic\",\"0\":\"CRK0\", \"1\":\"CRK1\", \"2\":\"CRK2\"}\n",
    "var0_key = {\"0\":\"Newtonian\",\"1\":\"Power Law\"} #Viscosity calc method\n",
    "plot_key = {\"Quintic\":[\"o\",\"#5ec962\"],\"CRK0\":[\"X\",\"#21918c\"], \"CRK1\":[\"s\",\"#3b528b\"],\"CRK2\":[\"d\",\"#440154\"],\n",
    "            \"Analytic\":[\"\",\"red\"],\"0\":\"dashed\",\"1\":\"dotted\"} #Viridis colors\n",
    "#################################\n",
    "# Simulation parameters\n",
    "#################################\n",
    "#System dimensions\n",
    "outer_R = 10\n",
    "R = 6.99\n",
    "d = 3 #3d\n",
    "#Fluid properties\n",
    "rho0 = 1\n",
    "gd0 = 1e-2\n",
    "npow=0.5\n",
    "#Scaling parameters\n",
    "nb =1\n",
    "#Frame (5 before end)\n",
    "frame = -1 #corresponds to t=3500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147bd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify filepath\n",
    "infilepath = '/ascldap/users/etpaler/test/rheo_bench/channel/03_23_2022_commit/ncdf'\n",
    "#Create dataframe of simulation parameters and run code for all runs\n",
    "data_files = generate_file_names(infilepath)\n",
    "generate_df(data_files,gen_col_names(namekey))\n",
    "#Create dictionary to store simulation data\n",
    "ss_data_dict = {} #dict for max velocity vs time data (to check steady state)\n",
    "uprof_data_dict = {} #dict for velocity as a function of x\n",
    "#Extract simulation data\n",
    "for run in data_files:\n",
    "    #data for ss_data_dict\n",
    "    u = ds[\"velocities\"][:,:,0]\n",
    "    max_u = np.max(u,axis=1)\n",
    "    t = ds[\"time\"][:]\n",
    "    t_prof = np.hstack((t[:,None],max_u[:,None]))\n",
    "    t_prof = t_prof[t_prof[:,0].argsort()]\n",
    "    ss_data_dict[run_info[-1]]=t_prof \n",
    "    \n",
    "    #data for uprof_data_dict    \n",
    "    t_frame, r, u_z = poiseuille_data(run, ds)\n",
    "    r_norm = r/R\n",
    "    u_z_norm = u_z/np.max(u_z)\n",
    "    #Reformat the data for plotting\n",
    "    u_prof = np.hstack((r_norm[:,None],u_z_norm[:,None]))\n",
    "    u_prof = u_prof[u_prof[:,0].argsort()]\n",
    "    #Only need R>0 because the data is symmetrical\n",
    "    u_prof = u_prof[np.logical_not(u_prof[:,0] < 0)]\n",
    "    uprof_data_dict[run_info[-1]]=u_prof "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0fba69-4160-40d4-a4d9-dd11fba30c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
